{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Develop a \"Tell-the-time\" network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stdlib\n",
    "import os\n",
    "from functools import partial\n",
    "\n",
    "# pip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras import layers\n",
    "from keras import backend as K\n",
    "\n",
    "# local\n",
    "from utils import get_dirs, train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRS = get_dirs(os.path.abspath('') + os.sep + 'Task2.ipynb')\n",
    "print('\\033[1m' + 'Directories:' + '\\033[0m')\n",
    "for dir_name, path in DIRS.items():\n",
    "    print(f'{dir_name:<7} {path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.load(DIRS['data'] + 'images.npy')\n",
    "labels = np.load(DIRS['data'] + 'labels.npy')\n",
    "\n",
    "images = images.astype('float32') / 255\n",
    "labels = labels.astype('int32')\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2)\n",
    "\n",
    "del images, labels\n",
    "\n",
    "print('\\033[1m' + 'Data:' + '\\033[0m')\n",
    "print('  name  |        shape      | dtype')\n",
    "print('--------+-------------------+-------')\n",
    "for name, arr in zip(['X_train', 'X_test', 'y_train', 'y_test'], [X_train, X_test, y_train, y_test]):\n",
    "    print(f'{name:<7} | {str(arr.shape):<17} | {arr.dtype}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm that the data is sufficiently shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_tr, size_te = len(y_train) // 5, len(y_test) // 5\n",
    "print('\\033[1m' + 'Average labels:' + '\\033[0m')\n",
    "print('train:', '\\t'.join([f'{np.mean(y_train[i*size_tr:(i+1)*size_tr]):.3f}' for i in range(5)]))\n",
    "print('test: ', '\\t'.join([f'{np.mean(y_test[i*size_te:(i+1)*size_te]):.3f}' for i in range(5)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions to get specific versions of the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regression_labels(y_train, y_test):\n",
    "    \"\"\"\n",
    "    Hours and minutes are merged into a single float value:\n",
    "        * (1, 30) -> 1.5\n",
    "        * (11, 15) -> 11.25\n",
    "    \"\"\"\n",
    "    reg_y_train = (y_train[:, 0] + y_train[:, 1] / 60).astype('float32')\n",
    "    reg_y_test  = (y_test[:, 0] + y_test[:, 1] / 60).astype('float32')\n",
    "    return reg_y_train, reg_y_test\n",
    "\n",
    "def get_class_24_labels(y_train, y_test):\n",
    "    \"\"\"\n",
    "    12 hours are split into 24 half-hour bins:\n",
    "        * (1, 30) -> 3 (one-hot vector)\n",
    "        * (11, 15) -> 22 (one-hot vector)\n",
    "    \"\"\"\n",
    "    class_y_train = (y_train[:, 0] * 2 + y_train[:, 1] // 30).astype('float32')\n",
    "    class_y_test  = (y_test[:, 0] * 2 + y_test[:, 1] // 30).astype('float32')\n",
    "    class_y_train = keras.utils.to_categorical(class_y_train, num_classes=24)\n",
    "    class_y_test = keras.utils.to_categorical(class_y_test, num_classes=24)\n",
    "    return class_y_train, class_y_test\n",
    "\n",
    "def get_class_48_labels(y_train, y_test):\n",
    "    \"\"\"\n",
    "    12 hours are split into 48 quarter-hour bins:\n",
    "        * (1, 30) -> 6 (one-hot vector)\n",
    "        * (11, 15) -> 45 (one-hot vector)\n",
    "    \"\"\"\n",
    "    class_y_train = (y_train[:, 0] * 4 + y_train[:, 1] // 15).astype('float32')\n",
    "    class_y_test  = (y_test[:, 0] * 4 + y_test[:, 1] // 15).astype('float32')\n",
    "    class_y_train = keras.utils.to_categorical(class_y_train, num_classes=48)\n",
    "    class_y_test = keras.utils.to_categorical(class_y_test, num_classes=48)\n",
    "    return class_y_train, class_y_test\n",
    "\n",
    "def get_multiclass_labels(y_train, y_test):\n",
    "    \"\"\"\n",
    "    Hours are returned as one-hot vectors and minutes are binned into 12 classes.\n",
    "    This results in 12 * 12 = 144 classes.\n",
    "    \"\"\"\n",
    "    hours_train = keras.utils.to_categorical(y_train[:, 0], num_classes=12)\n",
    "    hours_test  = keras.utils.to_categorical(y_test[:, 0], num_classes=12)\n",
    "    minutes_train = keras.utils.to_categorical(y_train[:, 1] // 5, num_classes=12)\n",
    "    minutes_test  = keras.utils.to_categorical(y_test[:, 1] // 5, num_classes=12)\n",
    "    class_y_train = np.array((hours_train, minutes_train))\n",
    "    class_y_test  = np.array((hours_test, minutes_test))\n",
    "    return class_y_train, class_y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define custom loss functions where 0:00 and 11:55 are just 5 minutes apart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cs_loss_1(y_true, y_pred):\n",
    "    \"\"\"Basic form of common sense loss\"\"\"\n",
    "    return K.abs(K.minimum(K.abs(y_true - y_pred), K.ones_like(y_true) * 12 - K.abs(y_true - y_pred)))\n",
    "\n",
    "def cs_loss_2(y_true, y_pred):\n",
    "    \"\"\"Common sense loss with fixed penalty for predictions <0\"\"\"\n",
    "    # punish negative predictions\n",
    "    penalty = 12 * K.sum(K.cast(K.less(y_pred, 0), 'float32'))\n",
    "    loss = K.abs(K.minimum(K.abs(y_true - y_pred), K.ones_like(y_true) * 12 - K.abs(y_true - y_pred)))\n",
    "    return loss + penalty\n",
    "\n",
    "def cs_loss_3(y_true, y_pred):\n",
    "    \"\"\"Common sense loss with scaled penalty for predictions <0 and >12\"\"\"\n",
    "    # punish negative predictions and predictions greater than 12\n",
    "    penalty = K.maximum(0.0, -y_pred) + K.maximum(0.0, y_pred - 12)\n",
    "    loss = K.minimum(K.abs(y_true - y_pred), K.ones_like(y_true) * 12 - K.abs(y_true - y_pred))\n",
    "    return loss + penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loss_fn(loss_fn):\n",
    "    tests = [[1.0, 1.0], [1.5, 1.25], [11.75, 0.25], [2.0, -10.0], [1.0, -1.0], [3.0, 15.0]]\n",
    "    print('\\033[1m' + f'{loss_fn.__name__}:' + '\\033[0m')\n",
    "    print(' true | pred  | loss')\n",
    "    print('------+-------+-----')\n",
    "    for test in tests:\n",
    "        print(f'{test[0]:<5} | {test[1]:<5} | {loss_fn(test[0], test[1])}')\n",
    "\n",
    "for loss_fn in [cs_loss_1, cs_loss_2, cs_loss_3]:\n",
    "    test_loss_fn(loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define custom activation function that maps -1 to 11, 13 to 1, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_activation(x):\n",
    "    x = K.switch(K.less(x, 0), 12 + x, x)\n",
    "    x = K.switch(K.greater(x, 12), x - 12, x)\n",
    "    return x\n",
    "\n",
    "for x in [1, 13, -1, 0, -10]:\n",
    "    print(f'{x:^3} -> {custom_activation(x)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heavy functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function that can build models for all of the different approaches to the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(problem_type: str) -> Model:\n",
    "    \"\"\"\n",
    "    Build and compile a model for the given problem type.\n",
    "    \n",
    "    Options:\n",
    "        * 'nrg' | naive regression\n",
    "        * 'cs1' | common sense regression with cs_loss_1\n",
    "        * 'cs2' | common sense regression with cs_loss_2\n",
    "        * 'cs3' | common sense regression with cs_loss_3\n",
    "        * 'cs4' | common sense regression with cs_loss_1 & custom_activation\n",
    "        * 'c24' | classification into 24 half-hour bins\n",
    "        * 'c48' | classification into 48 quarter-hour bins\n",
    "        * 'mhc' | multi-head classification: 12 hour bins, 12 (five) minute bins\n",
    "    \"\"\"\n",
    "    \n",
    "    if problem_type == 'nrg':\n",
    "        final_layer = layers.Dense(1)\n",
    "        loss, metrics = 'mse', ['mae']\n",
    "    elif problem_type in ['cs1', 'cs2', 'cs3']:\n",
    "        final_layer = layers.Dense(1)\n",
    "        loss = {'cs1': cs_loss_1, 'cs2': cs_loss_2, 'cs3': cs_loss_3}[problem_type]\n",
    "        metrics = ['mae']\n",
    "    elif problem_type == 'cs4':\n",
    "        final_layer = layers.Dense(1, activation=custom_activation)\n",
    "        loss = cs_loss_1\n",
    "        metrics = ['mae']\n",
    "    elif problem_type in ['c24', 'c48']:\n",
    "        final_layer = layers.Dense(24 if problem_type == 'c24' else 48, activation='softmax')\n",
    "        loss, metrics = 'categorical_crossentropy', ['accuracy']\n",
    "    elif problem_type == 'mhc':\n",
    "        final_layer = layers.Flatten()  # dummy, because we will add two heads later on\n",
    "        loss, metrics = ['categorical_crossentropy', 'categorical_crossentropy'], ['accuracy']\n",
    "    else:\n",
    "        raise ValueError(f'Unknown problem type: {problem_type}')\n",
    "\n",
    "    DefaultConv2D = partial(layers.Conv2D, kernel_initializer='he_normal', kernel_size=3, activation='elu', padding='SAME')\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(DefaultConv2D(filters=32, kernel_size=5, strides=(3, 3), input_shape=(150, 150, 1)))\n",
    "    model.add(layers.MaxPooling2D(pool_size=2))\n",
    "    model.add(DefaultConv2D(filters=64))\n",
    "    model.add(layers.MaxPooling2D(pool_size=2))\n",
    "    model.add(DefaultConv2D(filters=128))\n",
    "    model.add(layers.MaxPooling2D(pool_size=2))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(final_layer)\n",
    "\n",
    "    if problem_type == 'mhc':\n",
    "        output_hrs = layers.Dense(12, activation='softmax', name='hrs')(model.output)\n",
    "        output_min = layers.Dense(12, activation='softmax', name='min')(model.output)\n",
    "        model = Model(inputs=model.input, outputs=[output_hrs, output_min])\n",
    "\n",
    "    model.compile(loss=loss, optimizer='adam', metrics=metrics)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function that generates one batch of data at a time to save on RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(X_train, X_test, y_train, y_test, multiclass: bool = False, folds: int = 5):\n",
    "    \"\"\"\n",
    "    Generator function to yield data in batches that divide all data into n batches.\n",
    "    If multiclass is True, we first need to split y into y_hrs and y_min, because y.shape[0] = 2\n",
    "    \"\"\"\n",
    "    batch_size_train = X_train.shape[0] // folds\n",
    "    batch_size_test = X_test.shape[0] // folds\n",
    "    while True:\n",
    "        for i in range(folds):\n",
    "            _X_train = X_train[i*batch_size_train:(i+1)*batch_size_train]\n",
    "            _X_test = X_test[i*batch_size_test:(i+1)*batch_size_test]\n",
    "            if multiclass:\n",
    "                _y_train = [y_train[0][i*batch_size_train:(i+1)*batch_size_train], y_train[1][i*batch_size_train:(i+1)*batch_size_train]]\n",
    "                _y_test = [y_test[0][i*batch_size_test:(i+1)*batch_size_test], y_test[1][i*batch_size_test:(i+1)*batch_size_test]]\n",
    "            else:\n",
    "                _y_train = y_train[i*batch_size_train:(i+1)*batch_size_train]\n",
    "                _y_test = y_test[i*batch_size_test:(i+1)*batch_size_test]\n",
    "            yield _X_train, _y_train, _X_test, _y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"main\" function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(\n",
    "    problem_type: str,\n",
    "    X_train: np.ndarray,\n",
    "    y_train: np.ndarray,\n",
    "    X_test: np.ndarray,\n",
    "    y_test: np.ndarray,\n",
    "    passes: int = 5,\n",
    "    epochs: int = 10,\n",
    "    save_model: bool = False):\n",
    "    \"\"\"\n",
    "    Run an experiment for the given problem type.\n",
    "    \n",
    "    Options for problem_type:\n",
    "        * 'nrg' | naive regression\n",
    "        * 'cs1' | common sense regression with cs_loss_1\n",
    "        * 'cs2' | common sense regression with cs_loss_2\n",
    "        * 'cs3' | common sense regression with cs_loss_3\n",
    "        * 'cs4' | common sense regression with cs_loss_1 & custom_activation\n",
    "        * 'c24' | classification into 24 half-hour bins\n",
    "        * 'c48' | classification into 48 quarter-hour bins\n",
    "        * 'mhc' | multi-head classification: 12 hour bins, 12 (five) minute bins\n",
    "\n",
    "    Returns:\n",
    "        * loss history (train)\n",
    "        * metric history (train)\n",
    "        * test results\n",
    "\n",
    "    For the multi-head model, five dataframes are returned.\n",
    "\n",
    "    If save_model is True, the model is saved to a `<problem_type>.h5` file.\n",
    "    \"\"\"\n",
    "    \n",
    "    if problem_type in ['nrg', 'cs1', 'cs2', 'cs3', 'cs4']:\n",
    "        y_train, y_test = get_regression_labels(y_train, y_test)\n",
    "    elif problem_type == 'c24':\n",
    "        y_train, y_test = get_class_24_labels(y_train, y_test)\n",
    "    elif problem_type == 'c48':\n",
    "        y_train, y_test = get_class_48_labels(y_train, y_test)\n",
    "    elif problem_type == 'mhc':\n",
    "        y_train, y_test = get_multiclass_labels(y_train, y_test)\n",
    "    else:\n",
    "        raise ValueError(f'Unknown problem type: {problem_type}')\n",
    "\n",
    "    if problem_type == 'mhc':\n",
    "        # df_test will have each row representing a fold, with the columns being loss and metric\n",
    "        df_test = pd.DataFrame(columns=['total_loss', 'hrs_loss', 'min_loss', 'hrc_acc', 'min_acc'])\n",
    "        # df_train_... will be a list with each row representing an epoch, and each column representing a fold\n",
    "        df_train_loss_hrs = pd.DataFrame()\n",
    "        df_train_metric_hrs = pd.DataFrame()\n",
    "        df_train_loss_min = pd.DataFrame()\n",
    "        df_train_metric_min = pd.DataFrame()\n",
    "    else:\n",
    "        df_test = pd.DataFrame(columns=['loss', 'metric'])\n",
    "        df_train_loss = pd.DataFrame()\n",
    "        df_train_metric = pd.DataFrame()\n",
    "\n",
    "    model = build_model(problem_type)\n",
    "    folds = 5\n",
    "\n",
    "    get_batch = batch_generator(\n",
    "        X_train = X_train,\n",
    "        X_test = X_test,\n",
    "        y_train = y_train,\n",
    "        y_test = y_test,\n",
    "        multiclass = True if problem_type=='mhc' else False,\n",
    "        folds = folds\n",
    "    )\n",
    "\n",
    "    for p in range(passes):\n",
    "        print('\\n' + '\\033[1m' + '-' * 50 + '\\n' + f'Pass {p+1}/{passes}' + '\\033[0m')\n",
    "        for fold in range(folds):\n",
    "            print('\\n---\\n' + '\\033[1m' + f'Fold {fold+1}/{folds}' + '\\033[0m')\n",
    "            _X_train, _y_train, _X_test, _y_test = next(get_batch)\n",
    "\n",
    "            # train the model\n",
    "            print('\\033[1m' + 'Train' + '\\033[0m')\n",
    "            history = model.fit(_X_train, _y_train, epochs=epochs, verbose=1)\n",
    "\n",
    "            # evaluate the model\n",
    "            print('\\033[1m' + 'Test' + '\\033[0m')\n",
    "            results = model.evaluate(_X_test, _y_test, verbose=1)\n",
    "\n",
    "            # save the results\n",
    "            df_test.loc[p*folds + fold] = results\n",
    "            if problem_type != 'mhc':\n",
    "                df_train_loss[p*folds + fold] = history.history['loss']\n",
    "                df_train_metric[p*folds + fold] = history.history[list(history.history.keys())[1]]\n",
    "            else:\n",
    "                df_train_loss_hrs[p*folds + fold] = history.history['hrs_loss']\n",
    "                df_train_metric_hrs[p*folds + fold] = history.history['hrs_accuracy']\n",
    "                df_train_loss_min[p*folds + fold] = history.history['min_loss']\n",
    "                df_train_metric_min[p*folds + fold] = history.history['min_accuracy']\n",
    "\n",
    "        # save the model after each pass\n",
    "        if save_model:\n",
    "            model.save(DIRS['models'] + f'{problem_type}.h5')\n",
    "    del model\n",
    "\n",
    "    if problem_type == 'mhc':\n",
    "        # df_train_metric will be empty\n",
    "        return df_test, df_train_loss_hrs, df_train_metric_hrs, df_train_loss_min, df_train_metric_min\n",
    "    return df_test, df_train_loss, df_train_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_experiment = partial(\n",
    "    run_experiment,\n",
    "    X_train = X_train,\n",
    "    y_train = y_train,\n",
    "    X_test = X_test,\n",
    "    y_test = y_test,\n",
    "    passes = 5,\n",
    "    epochs = 10,\n",
    "    save_model = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we run the naive regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = DIRS['csv'] + os.sep + 'naive' + os.sep\n",
    "if not os.path.exists(target):\n",
    "    os.makedirs(target)\n",
    "\n",
    "df_test_nrg, df_train_loss_nrg, df_train_metric_nrg = default_experiment(problem_type='nrg')\n",
    "for df, name in zip(\n",
    "        [df_test_nrg, df_train_loss_nrg, df_train_metric_nrg],\n",
    "        ['test', 'train_loss', 'train_metric']\n",
    "    ):\n",
    "    df.to_csv(target + f'nrg_{name}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we run the common sense regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = DIRS['csv'] + os.sep + 'commonsense' + os.sep\n",
    "if not os.path.exists(target):\n",
    "    os.makedirs(target)\n",
    "for i in range(5):\n",
    "    df_test_cs, df_train_loss_cs, df_train_metric_cs = default_experiment(problem_type=f'cs{i}')\n",
    "    for df, name in zip(\n",
    "            [df_test_cs, df_train_loss_cs, df_train_metric_cs],\n",
    "            ['test', 'train_loss', 'train_metric']\n",
    "        ):\n",
    "        df.to_csv(target + f'cs{i}_{name}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we move on to the classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = DIRS['csv'] + os.sep + 'classify' + os.sep\n",
    "if not os.path.exists(target):\n",
    "    os.makedirs(target)\n",
    "for i in [24, 48]:\n",
    "    df_test_c, df_train_loss_c, df_train_metric_c = default_experiment(problem_type=f'c{i}')\n",
    "    for df, name in zip(\n",
    "            [df_test_c, df_train_loss_c, df_train_metric_c],\n",
    "            ['test', 'train_loss', 'train_metric']\n",
    "        ):\n",
    "        df.to_csv(target + f'c{i}_{name}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "last but not least, we run the multi-head classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = DIRS['csv'] + os.sep + 'multihead' + os.sep\n",
    "if not os.path.exists(target):\n",
    "    os.makedirs(target)\n",
    "df_test_mhc, df_train_loss_hrs_mhc, df_train_metric_hrs_mhc, df_train_loss_min_mhc, df_train_metric_min_mhc = default_experiment(problem_type='mhc')\n",
    "for df, name in zip(\n",
    "        [df_test_mhc, df_train_loss_hrs_mhc, df_train_metric_hrs_mhc, df_train_loss_min_mhc, df_train_metric_min_mhc],\n",
    "        ['test', 'train_loss_hrs', 'train_metric_hrs', 'train_loss_min', 'train_metric_min']\n",
    "    ):\n",
    "    df.to_csv(target + f'mhc_{name}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions that load a trained model and return the predictions for the test set as a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reg_predictions(\n",
    "    model_name: str,\n",
    "    X_test: np.ndarray,\n",
    "    y_test: np.ndarray,\n",
    "    ) -> tuple[pd.DataFrame, float]:\n",
    "    \"\"\"Get predictions and calculate MAE for the test set.\"\"\"\n",
    "    \n",
    "    custom_objects = None\n",
    "    if model_name in ['cs1', 'cs2', 'cs3']:\n",
    "        custom_objects = {f'cs_loss_{model_name[2]}': {'cs1': cs_loss_1, 'cs2': cs_loss_2, 'cs3': cs_loss_3}[model_name]}\n",
    "    elif model_name == 'cs4':\n",
    "        custom_objects = {'cs_loss_1': cs_loss_1, 'custom_activation': custom_activation}\n",
    "    \n",
    "    model = keras.models.load_model(DIRS['models'] + model_name + '.h5', custom_objects=custom_objects)\n",
    "    df = pd.DataFrame(columns=['true', 'pred'])\n",
    "    y_pred = model.predict(X_test, verbose=0)\n",
    "    df['true'] = y_test\n",
    "    df['pred'] = y_pred\n",
    "    mae = df['true'].sub(df['pred']).abs().mean()\n",
    "    del model\n",
    "    return df, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_predictions(\n",
    "    model_name: str,\n",
    "    X_test: np.ndarray,\n",
    "    y_test: np.ndarray,\n",
    "    ) -> tuple[pd.DataFrame, float]:\n",
    "    \"\"\"Get predictions and calculate accuracy for the test set.\"\"\"\n",
    "    \n",
    "    model = keras.models.load_model(DIRS['models'] + model_name + '.h5')\n",
    "    y_pred = model.predict(X_test, verbose=0)\n",
    "    if model_name != 'mhc':\n",
    "        df = pd.DataFrame(columns=['true', 'pred'])\n",
    "        df['true'], df['pred'] = y_test.argmax(axis=1), y_pred.argmax(axis=1)\n",
    "        acc = (df['true'] == df['pred']).mean()\n",
    "    else:\n",
    "        df = pd.DataFrame(columns=['true_hrs', 'pred_hrs', 'true_min', 'pred_min'])\n",
    "        df['true_hrs'], df['pred_hrs'] = y_test[0].argmax(axis=1), y_pred[0].argmax(axis=1)\n",
    "        df['true_min'], df['pred_min'] = y_test[1].argmax(axis=1), y_pred[1].argmax(axis=1)\n",
    "        acc = (\n",
    "            (df['true_hrs'] == df['pred_hrs']).mean()\n",
    "            + (df['true_min'] == df['pred_min']).mean()\n",
    "        ) / 2\n",
    "    del model\n",
    "    return df, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function that clusters the prediction data and fits one or two regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clusters(df: pd.DataFrame, method: str = 'km') -> tuple[list[pd.DataFrame], list[float]]:\n",
    "    \"\"\"\n",
    "    Divide the dataframe into clusters and also add regression data to the returned dataframes.\n",
    "    Options for method: 'kmeans' (with k=2), 'dbscan'.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    if method == 'kmeans':\n",
    "        kmeans = KMeans(n_clusters=2)\n",
    "        kmeans.fit(df)\n",
    "        df['cluster'] = kmeans.labels_\n",
    "        # calculate linear regression for both clusters separately\n",
    "        df1 = df[df['cluster'] == 0].copy()\n",
    "        df2 = df[df['cluster'] == 1].copy()\n",
    "        lr1 = LinearRegression().fit(df1['true'].values.reshape(-1, 1), df1['pred'].values.reshape(-1, 1))\n",
    "        lr2 = LinearRegression().fit(df2['true'].values.reshape(-1, 1), df2['pred'].values.reshape(-1, 1))\n",
    "        # predict\n",
    "        df1['reg'] = lr1.predict(df1['true'].values.reshape(-1, 1))\n",
    "        df2['reg'] = lr2.predict(df2['true'].values.reshape(-1, 1))\n",
    "        return [df1, df2], [lr1.coef_[0][0], lr2.coef_[0][0]]\n",
    "    elif method == 'dbscan':\n",
    "        dbscan = DBSCAN()\n",
    "        dbscan.fit(df)\n",
    "        df['cluster'] = dbscan.labels_\n",
    "        n_clusters = len(set(dbscan.labels_)) - (1 if -1 in dbscan.labels_ else 0)\n",
    "        dfs = [df[df['cluster'] == i].copy() for i in range(n_clusters)]\n",
    "        # biggest cluster\n",
    "        dfs.sort(key=lambda x: len(x), reverse=True)\n",
    "        main_cluster = dfs[0]\n",
    "        # calculate linear regression for main cluster\n",
    "        lr = LinearRegression().fit(main_cluster['true'].values.reshape(-1, 1), main_cluster['pred'].values.reshape(-1, 1))\n",
    "        main_cluster['reg'] = lr.predict(main_cluster['true'].values.reshape(-1, 1))\n",
    "        dfs[0] = main_cluster\n",
    "        return dfs, [lr.coef_[0][0]]\n",
    "    else:\n",
    "        raise ValueError('Invalid method')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function that creates an actual scatterplot for a regression model's predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scatterplot(clusters: list[pd.DataFrame], slopes: list, title: str = None) -> plt.Figure:\n",
    "    \"\"\"Get a scatterplot with regression lines for each cluster.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    for i, cluster in enumerate(clusters):\n",
    "        color = 'tab:blue' if i == 0 else 'tab:green'\n",
    "        ax.plot(cluster['true'], cluster['pred'], 'o', color=color, alpha=0.1, zorder=1)\n",
    "        reg_color = 'tab:red' if i == 0 else 'tab:orange'\n",
    "        try:  # only plot if we have a regression line for this cluster\n",
    "            ax.plot(cluster['true'], cluster['reg'], color=reg_color, label=f'${slopes[i]:.2f}$', zorder=2)\n",
    "        except KeyError:\n",
    "            pass\n",
    "    ax.plot([0, 12], [0, 12], '--', color='tab:gray', zorder=0)\n",
    "    ax.hlines(0, 0, 12, color='tab:gray', zorder=0)\n",
    "    ax.hlines(12, 0, 12, color='tab:gray', zorder=0)\n",
    "    ax.set_xlabel('true')\n",
    "    ax.set_ylabel('predicted')\n",
    "    ax.legend(title='slope')\n",
    "    if title is not None:\n",
    "        ax.set_title(title, weight='bold')\n",
    "    fig.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we want to visualize the naive regression predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, reg_y_test = get_regression_labels(y_train, y_test)\n",
    "del _\n",
    "naive_pred, naive_mae = get_reg_predictions('nrg', X_test, reg_y_test)\n",
    "\n",
    "x, y = naive_pred['true'], naive_pred['pred']\n",
    "p = np.poly1d(np.polyfit(x, y, 3))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.plot(x, y, 'o', color='tab:blue', alpha=0.1, zorder=1)\n",
    "ax.scatter(x, p(x), s=1, c='tab:red', zorder=2)\n",
    "ax.plot([0, 12], [0, 12], '--', color='tab:gray', zorder=0)\n",
    "ax.hlines(0, 0, 12, color='tab:gray', zorder=0)\n",
    "ax.hlines(12, 0, 12, color='tab:gray', zorder=0)\n",
    "ax.set_xlabel('true')\n",
    "ax.set_ylabel('predicted')\n",
    "ax.set_title(f'Naive Approach (mae = {naive_mae:.3f})', weight='bold')\n",
    "fig.tight_layout()\n",
    "fig.savefig(DIRS['plots']+ 'nrg_acc.png', dpi=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we also want to visualize how our different custom loss functions perform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, reg_y_test = get_regression_labels(y_train, y_test)\n",
    "del _\n",
    "for model_name in ['cs1', 'cs2', 'cs3', 'cs4']:\n",
    "    pred, mae = get_reg_predictions(model_name, X_test, reg_y_test)\n",
    "    method = 'dbscan' if model_name in ['cs3', 'cs4'] else 'kmeans'\n",
    "    clusters, slopes = get_clusters(pred, method=method)\n",
    "    fig = get_scatterplot(clusters, slopes, title=f'Common Sense Loss {model_name[2]} (mae = {mae:.3f})')\n",
    "    fig.savefig(DIRS['plots'] + f'{model_name}_acc.png', dpi=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load classification predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, class_24_y_test = get_class_24_labels(y_train, y_test)\n",
    "pred_24, acc_24 = get_class_predictions('c24', X_test, class_24_y_test)\n",
    "del _, class_24_y_test\n",
    "\n",
    "_, class_48_y_test = get_class_48_labels(y_train, y_test)\n",
    "pred_48, acc_48 = get_class_predictions('c48', X_test, class_48_y_test)\n",
    "del _, class_48_y_test\n",
    "\n",
    "_, mhc_y_test = get_multiclass_labels(y_train, y_test)\n",
    "pred_mhc, acc_mhc = get_class_predictions('mhc', X_test, mhc_y_test)\n",
    "del _, mhc_y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the simple classifier results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pred, acc in zip([pred_24, pred_48], [acc_24, acc_48]):\n",
    "    cm = confusion_matrix(pred['pred'], pred['true'])\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    ax.imshow(cm, cmap='Reds')\n",
    "    \n",
    "    r = cm.shape[0]\n",
    "    ax.set_xticks(np.arange(0, r, r//12))\n",
    "    ax.set_yticks(np.arange(0, r, r//12))\n",
    "    ax.set_xticklabels([f'{i:02d}:00' for i in range(0, 24, 2)])\n",
    "    ax.set_yticklabels([f'{i:02d}:00' for i in range(0, 24, 2)])\n",
    "    plt.setp(ax.get_xticklabels(), rotation=-45, ha='left', rotation_mode='anchor')\n",
    "    \n",
    "    ax.set_xlabel('true')\n",
    "    ax.set_ylabel('predicted')\n",
    "    ax.set_title(f'{r} Classes (acc. = {acc*100:.1f}%)', weight='bold')\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(DIRS['plots'] + f'c{r}_acc.png', dpi=500)\n",
    "\n",
    "del pred_24, pred_48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally the multihead classifier results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "cm_hrs = confusion_matrix(pred_mhc['pred_hrs'], pred_mhc['true_hrs'])\n",
    "cm_min = confusion_matrix(pred_mhc['pred_min'], pred_mhc['true_min'])\n",
    "\n",
    "ax1.imshow(cm_hrs, cmap='Reds')\n",
    "ax1.set_xticks(np.arange(0, 12)); ax1.set_yticks(np.arange(0, 12))\n",
    "ax1.set_title('Hours')\n",
    "\n",
    "ax2.imshow(cm_min, cmap='Reds')\n",
    "ax2.set_xticks(np.arange(0, 12)); ax2.set_yticks(np.arange(0, 12))\n",
    "ax2.set_xticklabels(np.arange(0, 60, 5)); ax2.set_yticklabels(np.arange(0, 60, 5))\n",
    "ax2.set_title('Minutes')\n",
    "fig.supxlabel('true')\n",
    "fig.supylabel('predicted')\n",
    "fig.suptitle(f'Multihead (acc. = {acc_mhc*100:.1f}%)', weight='bold')\n",
    "fig.tight_layout()\n",
    "fig.savefig(DIRS['plots'] + 'mhc_acc.png', dpi=500)\n",
    "\n",
    "del pred_mhc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### History plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(model_name: str) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Loads both train and test histories (loss+metrics) from csv files and returns it as two DataFrames.\"\"\"\n",
    "    train_loss = pd.read_csv(DIRS['csv'] + f'{model_name}_train_loss.csv', index_col=0)\n",
    "    train_metric = pd.read_csv(DIRS['csv'] + f'{model_name}_train_metric.csv', index_col=0)\n",
    "    df_test = pd.read_csv(DIRS['csv'] + f'{model_name}_test.csv', index_col=0)\n",
    "    # train_loss and train_metric have n_folds*n_passes columns and n_epochs rows\n",
    "    # we want to have n_folds*n_passes*n_epochs rows and 2 columns\n",
    "    train_loss = train_loss.melt(var_name='leg', value_name='loss')\n",
    "    train_metric = train_metric.melt(var_name='leg', value_name='metric')\n",
    "    # merge the two DataFrames so we get loss, metric as columns, we don't care about the leg column\n",
    "    df_train = pd.merge(train_loss, train_metric, left_index=True, right_index=True).drop(columns=['leg_x', 'leg_y'])\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_history_plot(\n",
    "    df_train: pd.DataFrame,\n",
    "    df_test: pd.DataFrame,\n",
    "    title: str,\n",
    "    log_scale: bool = False\n",
    "    ) -> plt.Figure:\n",
    "    \"\"\"Returns a figure with the train and test loss and metric plots.\"\"\"\n",
    "    test_locs = [9 + i for i in range(0, 250, 10)]\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(5, 5))\n",
    "    ax1.plot(df_train['loss'], 'o', alpha=0.25, zorder=1, color='tab:blue', label='train')\n",
    "    ax1.plot(df_train['loss'].rolling(10).mean(), zorder=2, color='tab:blue', label='train (smoothed)')\n",
    "    ax1.scatter(test_locs, df_test['loss'], marker='x', zorder=3, color='tab:red', label='test')\n",
    "    ax1.set_ylabel('Loss')\n",
    "\n",
    "    ax2.plot(df_train['metric'], 'o', alpha=0.25, zorder=1, color='tab:blue', label='train')\n",
    "    ax2.plot(df_train['metric'].rolling(10).mean(), zorder=2, color='tab:blue', label='train (smoothed)')\n",
    "    ax2.scatter(test_locs, df_test['metric'], marker='x', zorder=3, color='tab:red', label='test')\n",
    "    ax2.set_ylabel('Metric')\n",
    "\n",
    "    if log_scale:\n",
    "        ax1.set_yscale('log')\n",
    "        ax2.set_yscale('log')\n",
    "\n",
    "    fig.supxlabel('epoch')\n",
    "    fig.tight_layout()\n",
    "    fig.suptitle(title, weight='bold')\n",
    "    fig.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrg_df_train, nrg_df_test = load_data('naive' + os.sep + 'nrg')\n",
    "nrg_fig = get_history_plot(nrg_df_train, nrg_df_test, 'Naive Regression')\n",
    "nrg_fig.savefig(DIRS['plots'] + 'nrg_history.png', dpi=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common sense regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 5):\n",
    "    model_name = f'cs{i}'\n",
    "    df_train, df_test = load_data('commonsense' + os.sep + model_name)\n",
    "    fig = get_history_plot(df_train, df_test, title=f'Common Sense {i}')\n",
    "    fig.savefig(DIRS['plots'] + f'{model_name}_history.png', dpi=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [24, 48]:\n",
    "    model_name = f'c{i}'\n",
    "    df_train, df_test = load_data('classify' + os.sep + model_name)\n",
    "    fig = get_history_plot(df_train, df_test, title=f'{i} Classes')\n",
    "    fig.savefig(DIRS['plots'] + f'{model_name}_history.png', dpi=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The multihead model results are stored in a different way, so we need to load them differently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_loc = DIRS['csv'] + 'multihead' + os.sep\n",
    "mhc_df_train_loss_hrs = pd.read_csv(csv_loc + 'mhc_train_loss_hrs.csv', index_col=0)\n",
    "mhc_df_train_loss_hrs = mhc_df_train_loss_hrs.melt(var_name='leg', value_name='loss')\n",
    "mhc_df_train_metric_hrs = pd.read_csv(csv_loc + 'mhc_train_metric_hrs.csv', index_col=0)\n",
    "mhc_df_train_metric_hrs = mhc_df_train_metric_hrs.melt(var_name='leg', value_name='metric')\n",
    "mhc_df_train_hrs = pd.merge(mhc_df_train_loss_hrs, mhc_df_train_metric_hrs, left_index=True, right_index=True).drop(columns=['leg_x', 'leg_y'])\n",
    "\n",
    "mhc_df_train_loss_min = pd.read_csv(csv_loc + 'mhc_train_loss_min.csv', index_col=0)\n",
    "mhc_df_train_loss_min = mhc_df_train_loss_min.melt(var_name='leg', value_name='loss')\n",
    "mhc_df_train_metric_min = pd.read_csv(csv_loc + 'mhc_train_metric_min.csv', index_col=0)\n",
    "mhc_df_train_metric_min = mhc_df_train_metric_min.melt(var_name='leg', value_name='metric')\n",
    "mhc_df_train_min = pd.merge(mhc_df_train_loss_min, mhc_df_train_metric_min, left_index=True, right_index=True).drop(columns=['leg_x', 'leg_y'])\n",
    "\n",
    "mhc_df_test = pd.read_csv(csv_loc + 'mhc_test.csv', index_col=0)\n",
    "mhc_df_test_hrs = mhc_df_test[[col for col in mhc_df_test.columns if 'hrs' in col]].rename(columns=lambda x: x.replace('acc', 'metric').replace('hrs_', ''))\n",
    "mhc_df_test_min = mhc_df_test[[col for col in mhc_df_test.columns if 'min' in col]].rename(columns=lambda x: x.replace('acc', 'metric').replace('min_', ''))\n",
    "\n",
    "mhc_fig_hrs = get_history_plot(mhc_df_train_hrs, mhc_df_test_hrs, title='Multi-Head (Hours)')\n",
    "mhc_fig_hrs.savefig(DIRS['plots'] + 'mhc_hrs_history.png', dpi=500)\n",
    "mhc_fig_min = get_history_plot(mhc_df_train_min, mhc_df_test_min, title='Multi-Head (Minutes)')\n",
    "mhc_fig_min.savefig(DIRS['plots'] + 'mhc_min_history.png', dpi=500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "73a50edc90de9e6c73e4de59c0149da437672aa3b7b7e4f31799c5ff4b4c231b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
