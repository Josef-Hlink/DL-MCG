{"cells":[{"cell_type":"markdown","metadata":{},"source":["Imports"]},{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2021-11-10T13:01:43.598562Z","iopub.status.busy":"2021-11-10T13:01:43.598284Z","iopub.status.idle":"2021-11-10T13:01:52.166704Z","shell.execute_reply":"2021-11-10T13:01:52.165866Z","shell.execute_reply.started":"2021-11-10T13:01:43.598507Z"},"trusted":true},"outputs":[],"source":["# stdlib\n","import os\n","from time import perf_counter\n","\n","# pip\n","import numpy as np\n","import pandas as pd\n","from sklearn.metrics import confusion_matrix\n","import matplotlib.pyplot as plt\n","from tensorflow import keras\n","from keras import layers\n","from keras import backend as K\n","\n","# pretrained imagenet ResNets\n","from classification_models.tfkeras import Classifiers\n","\n","# local\n","from utils import get_dirs, train_test_split"]},{"cell_type":"markdown","metadata":{},"source":["Load and pre-process data to be compatible with the ResNet model"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1mDirectories:\u001b[0m\n","data    c:\\Users\\wille\\Documents\\GitHub\\MCG\\data\\\n","results c:\\Users\\wille\\Documents\\GitHub\\MCG\\results\\\n","csv     c:\\Users\\wille\\Documents\\GitHub\\MCG\\results\\csv\\\n","plots   c:\\Users\\wille\\Documents\\GitHub\\MCG\\results\\plots\\\n","figs    c:\\Users\\wille\\Documents\\GitHub\\MCG\\results\\figs\\\n","models  c:\\Users\\wille\\Documents\\GitHub\\MCG\\results\\models\\\n","\n","\u001b[1mData:\u001b[0m\n","X_train (14400, 150, 150, 3) float32\n","X_test  (3600, 150, 150, 3)  float32\n","y_train (14400, 2)           int32\n","y_test  (3600, 2)            int32\n"]}],"source":["DIRS = get_dirs(os.path.abspath('') + os.sep + 'Task2_help.ipynb')\n","print('\\033[1m' + 'Directories:' + '\\033[0m')\n","for dir_name, path in DIRS.items():\n","    print(f'{dir_name:<7} {path}')\n","\n","images = np.load(DIRS['data'] + 'images.npy')\n","labels = np.load(DIRS['data'] + 'labels.npy')\n","\n","X = np.stack([images]*3, axis=-1)  # (18000 x 150 x 150) -> (18000 x 150 x 150 x 3)\n","y = labels.astype('int32')\n","\n","np.random.seed(42)\n","\n","X_train, X_test, y_train, y_test = train_test_split(X=X, y=y, test_size=0.2)\n","X_train = X_train.astype('float32') / 255.0\n","X_test = X_test.astype('float32') / 255.0\n","\n","# create regression labels\n","# (4, 30) -> 4.5\n","# (11, 15) -> 11.25\n","reg_y_train = (y_train[:, 0] + y_train[:, 1] / 60).astype('float32')\n","reg_y_test  = (y_test[:, 0] + y_test[:, 1] / 60).astype('float32')\n","\n","# create classification labels where the 12 hours are split into 48 quarter-hour bins\n","# (4, 30) -> 18\n","# (11, 15) -> 45\n","class_y_train = (y_train[:, 0] * 4 + y_train[:, 1] // 15).astype('float32')\n","class_y_test  = (y_test[:, 0] * 4 + y_test[:, 1] // 15).astype('float32')\n","# one hot encoding\n","class_y_train = keras.utils.to_categorical(class_y_train, num_classes=48)\n","class_y_test = keras.utils.to_categorical(class_y_test, num_classes=48)\n","\n","#create classifcation labels where the 12 hours are split 12 hours and the minutes are split into 12 bins\n","\n","classhours_y_train = (y_train[:, 0]).astype('float32')\n","classhours_y_test  = (y_test[:, 0]).astype('float32')\n","classminutes_y_train = (y_train[:, 1] // 5).astype('float32')\n","classminutes_y_test  = (y_test[:, 1] // 5).astype('float32')\n","# one hot encoding\n","classhours_y_train = keras.utils.to_categorical(classhours_y_train, num_classes=12)\n","classhours_y_test = keras.utils.to_categorical(classhours_y_test, num_classes=12)\n","classminutes_y_train = keras.utils.to_categorical(classminutes_y_train, num_classes=12)\n","classminutes_y_test = keras.utils.to_categorical(classminutes_y_test, num_classes=12)\n","\n","\n","del images, labels, X, y\n","\n","print('\\n' + '\\033[1m' + 'Data:' + '\\033[0m')\n","for name, arr in zip(['X_train', 'X_test', 'y_train', 'y_test'], [X_train, X_test, y_train, y_test]):\n","    print(f'{name:<7} {str(arr.shape):<20} {arr.dtype}')"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2021-11-10T13:01:52.169559Z","iopub.status.busy":"2021-11-10T13:01:52.169251Z","iopub.status.idle":"2021-11-10T13:01:52.179226Z","shell.execute_reply":"2021-11-10T13:01:52.177574Z","shell.execute_reply.started":"2021-11-10T13:01:52.169505Z"},"trusted":true},"outputs":[],"source":["def cs_loss(y_true, y_pred):\n","    return K.minimum(K.abs(y_true - y_pred), K.abs(K.ones_like(y_pred) * 12 - K.abs(y_true - y_pred)))\n","\n","def sigmoid_12(x):\n","    # sigmoid function with range 0 to 12\n","    return 12 / (1 + K.exp(-x))\n","\n","\n","def build_resnet() -> keras.Model:\n","    \"\"\"\n","    ResNet model pretrained on 1000 class imagenet data set\n","    ResNet 34 is loaded (34 deep convolutional layers)\n","    The top of the ResNet model is excluded\n","    Three layers are added to end of ResNet, a GAPooling and two dense layers\n","    Last layer has linear activation to predict a continuous regression value\n","    \"\"\"\n","\n","    # load base model\n","    ResNet, _ = Classifiers.get('resnet34')\n","    base_model = ResNet(input_shape=(150, 150, 3), weights='imagenet', include_top=False)\n","    \n","    # add top layers\n","    pooled = layers.GlobalAveragePooling2D()(base_model.output)\n","    flatten = layers.Dense(256, activation='relu')(pooled)\n","    # final layer gets 48 nodes with softmax\n","    final1 = layers.Dense(12, activation='softmax')(flatten)\n","    final2 = layers.Dense(12, activation='softmax')(flatten)\n","\n","\n","    # create and compile Keras model object\n","    model = keras.Model(inputs=base_model.input, outputs=[final1, final2])\n","    model.compile(optimizer='adam', loss=['categorical_crossentropy', 'categorical_crossentropy'], metrics=['accuracy', 'accuracy'])\n","    \n","    return model"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2021-11-10T13:01:54.28244Z","iopub.status.busy":"2021-11-10T13:01:54.282014Z","iopub.status.idle":"2021-11-10T13:07:30.734626Z","shell.execute_reply":"2021-11-10T13:07:30.73335Z","shell.execute_reply.started":"2021-11-10T13:01:54.282403Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://github.com/qubvel/classification_models/releases/download/0.0.1/resnet34_imagenet_1000_no_top.h5\n","15548416/85521592 [====>.........................] - ETA: 10s"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn [6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[39m=\u001b[39m build_resnet()\n\u001b[0;32m      3\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mmae\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtotall_loss\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mhourloss\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mminuteloss\u001b[39m\u001b[39m'\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtrain_time\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtest_time\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      5\u001b[0m folds \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m\n","Cell \u001b[1;32mIn [5], line 20\u001b[0m, in \u001b[0;36mbuild_resnet\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39m# load base model\u001b[39;00m\n\u001b[0;32m     19\u001b[0m ResNet, _ \u001b[39m=\u001b[39m Classifiers\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mresnet34\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m base_model \u001b[39m=\u001b[39m ResNet(input_shape\u001b[39m=\u001b[39;49m(\u001b[39m150\u001b[39;49m, \u001b[39m150\u001b[39;49m, \u001b[39m3\u001b[39;49m), weights\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mimagenet\u001b[39;49m\u001b[39m'\u001b[39;49m, include_top\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     22\u001b[0m \u001b[39m# add top layers\u001b[39;00m\n\u001b[0;32m     23\u001b[0m pooled \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39mGlobalAveragePooling2D()(base_model\u001b[39m.\u001b[39moutput)\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\classification_models\\models_factory.py:78\u001b[0m, in \u001b[0;36mModelsFactory.inject_submodules.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m modules_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_kwargs()\n\u001b[0;32m     77\u001b[0m new_kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39mlist\u001b[39m(kwargs\u001b[39m.\u001b[39mitems()) \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(modules_kwargs\u001b[39m.\u001b[39mitems()))\n\u001b[1;32m---> 78\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mnew_kwargs)\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\classification_models\\models\\resnet.py:314\u001b[0m, in \u001b[0;36mResNet34\u001b[1;34m(input_shape, input_tensor, weights, classes, include_top, **kwargs)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mResNet34\u001b[39m(input_shape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, input_tensor\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, weights\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, classes\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m, include_top\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 314\u001b[0m     \u001b[39mreturn\u001b[39;00m ResNet(\n\u001b[0;32m    315\u001b[0m         MODELS_PARAMS[\u001b[39m'\u001b[39m\u001b[39mresnet34\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m    316\u001b[0m         input_shape\u001b[39m=\u001b[39minput_shape,\n\u001b[0;32m    317\u001b[0m         input_tensor\u001b[39m=\u001b[39minput_tensor,\n\u001b[0;32m    318\u001b[0m         include_top\u001b[39m=\u001b[39minclude_top,\n\u001b[0;32m    319\u001b[0m         classes\u001b[39m=\u001b[39mclasses,\n\u001b[0;32m    320\u001b[0m         weights\u001b[39m=\u001b[39mweights,\n\u001b[0;32m    321\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    322\u001b[0m     )\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\classification_models\\models\\resnet.py:280\u001b[0m, in \u001b[0;36mResNet\u001b[1;34m(model_params, input_shape, input_tensor, include_top, classes, weights, **kwargs)\u001b[0m\n\u001b[0;32m    278\u001b[0m         model\u001b[39m.\u001b[39mload_weights(weights)\n\u001b[0;32m    279\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 280\u001b[0m         load_model_weights(model, model_params\u001b[39m.\u001b[39mmodel_name,\n\u001b[0;32m    281\u001b[0m                            weights, classes, include_top, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    283\u001b[0m \u001b[39mreturn\u001b[39;00m model\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\classification_models\\weights.py:25\u001b[0m, in \u001b[0;36mload_model_weights\u001b[1;34m(model, model_name, dataset, classes, include_top, **kwargs)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[39mif\u001b[39;00m include_top \u001b[39mand\u001b[39;00m weights[\u001b[39m'\u001b[39m\u001b[39mclasses\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m!=\u001b[39m classes:\n\u001b[0;32m     22\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mIf using `weights` and `include_top`\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     23\u001b[0m                          \u001b[39m'\u001b[39m\u001b[39m as true, `classes` should be \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(weights[\u001b[39m'\u001b[39m\u001b[39mclasses\u001b[39m\u001b[39m'\u001b[39m]))\n\u001b[1;32m---> 25\u001b[0m     weights_path \u001b[39m=\u001b[39m keras_utils\u001b[39m.\u001b[39;49mget_file(\n\u001b[0;32m     26\u001b[0m         weights[\u001b[39m'\u001b[39;49m\u001b[39mname\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m     27\u001b[0m         weights[\u001b[39m'\u001b[39;49m\u001b[39murl\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m     28\u001b[0m         cache_subdir\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmodels\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m     29\u001b[0m         md5_hash\u001b[39m=\u001b[39;49mweights[\u001b[39m'\u001b[39;49m\u001b[39mmd5\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[0;32m     30\u001b[0m     )\n\u001b[0;32m     32\u001b[0m     model\u001b[39m.\u001b[39mload_weights(weights_path)\n\u001b[0;32m     34\u001b[0m \u001b[39melse\u001b[39;00m:\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\utils\\data_utils.py:296\u001b[0m, in \u001b[0;36mget_file\u001b[1;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir)\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    295\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 296\u001b[0m         urlretrieve(origin, fpath, DLProgbar())\n\u001b[0;32m    297\u001b[0m     \u001b[39mexcept\u001b[39;00m urllib\u001b[39m.\u001b[39merror\u001b[39m.\u001b[39mHTTPError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    298\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(error_msg\u001b[39m.\u001b[39mformat(origin, e\u001b[39m.\u001b[39mcode, e\u001b[39m.\u001b[39mmsg))\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\utils\\data_utils.py:86\u001b[0m, in \u001b[0;36murlretrieve\u001b[1;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[0;32m     84\u001b[0m response \u001b[39m=\u001b[39m urlopen(url, data)\n\u001b[0;32m     85\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(filename, \u001b[39m\"\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m fd:\n\u001b[1;32m---> 86\u001b[0m     \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m chunk_read(response, reporthook\u001b[39m=\u001b[39mreporthook):\n\u001b[0;32m     87\u001b[0m         fd\u001b[39m.\u001b[39mwrite(chunk)\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\utils\\data_utils.py:75\u001b[0m, in \u001b[0;36murlretrieve.<locals>.chunk_read\u001b[1;34m(response, chunk_size, reporthook)\u001b[0m\n\u001b[0;32m     73\u001b[0m count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     74\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m---> 75\u001b[0m     chunk \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39;49mread(chunk_size)\n\u001b[0;32m     76\u001b[0m     count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     77\u001b[0m     \u001b[39mif\u001b[39;00m reporthook \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n","File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2288.0_x64__qbz5n2kfra8p0\\lib\\http\\client.py:465\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m amt \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength:\n\u001b[0;32m    463\u001b[0m     \u001b[39m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[0;32m    464\u001b[0m     amt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength\n\u001b[1;32m--> 465\u001b[0m s \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mread(amt)\n\u001b[0;32m    466\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m s \u001b[39mand\u001b[39;00m amt:\n\u001b[0;32m    467\u001b[0m     \u001b[39m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[0;32m    468\u001b[0m     \u001b[39m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[0;32m    469\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_conn()\n","File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2288.0_x64__qbz5n2kfra8p0\\lib\\socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[0;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[0;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n","File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2288.0_x64__qbz5n2kfra8p0\\lib\\ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1271\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1272\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   1273\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[1;32m-> 1274\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[0;32m   1275\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1276\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n","File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2288.0_x64__qbz5n2kfra8p0\\lib\\ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1128\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1129\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1130\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[0;32m   1131\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1132\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["model = build_resnet()\n","\n","df = pd.DataFrame(columns=['mae', 'totall_loss', 'hourloss', 'minuteloss' 'train_time', 'test_time'])\n","\n","folds = 5\n","fold_size_train = X_train.shape[0] // folds\n","fold_size_test = X_test.shape[0] // folds\n","\n","for fold in range(folds):\n","    print(f'\\n---\\n' + '\\033[1m' + f'Fold {fold+1}/{folds}' + '\\033[0m' + '\\n')\n","    # slice the arrays\n","    X_train_fold = X_train[fold * fold_size_train : (fold + 1) * fold_size_train]\n","    X_test_fold = X_test[fold * fold_size_test : (fold + 1) * fold_size_test]\n","    y_train_fold_hours = classhours_y_train[fold * fold_size_train : (fold + 1) * fold_size_train]\n","    y_train_fold_minutes = classminutes_y_train[fold * fold_size_train : (fold + 1) * fold_size_train]\n","    y_test_fold_hours = classhours_y_test[fold * fold_size_test : (fold + 1) * fold_size_test]\n","    y_test_fold_minutes = classminutes_y_test[fold * fold_size_test : (fold + 1) * fold_size_test]\n","\n","    # train the model\n","    tic_train = perf_counter()\n","    history = model.fit(X_train_fold, [y_train_fold_hours, y_train_fold_minutes], epochs=10, batch_size=32, verbose=1)\n","    toc_train = perf_counter()\n","\n","    # evaluate the model\n","    tic_test = perf_counter()\n","    totalLoss, hourloss, minuteloss = model.evaluate(X_test_fold, [y_test_fold_hours, y_test_fold_minutes], verbose=0)\n","    toc_test = perf_counter()\n","\n","    # store the results\n","    df.loc[fold] = [mae, totalLoss, hourloss, minuteloss, toc_train - tic_train, toc_test - tic_test]\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# save results\n","model.save(DIRS['models'] + 'clock_class_48.h5')\n","df.to_csv(DIRS['csv'] + 'clock_class_48.csv', index=False)\n","df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_pred = model.predict(X_test)\n","y_pred = np.argmax(y_pred, axis=1)\n","y_test = np.argmax(class_y_test, axis=1)\n","\n","cm = confusion_matrix(y_test, y_pred)\n","accuracy = np.sum(y_pred == y_test) / y_test.shape[0]\n","print(f'Accuracy: {accuracy:.2%}')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig, ax = plt.subplots(figsize=(10, 10))\n","ax.imshow(cm, cmap='Reds')\n","# colorbar\n","cbar = fig.colorbar(ax.images[0], shrink=0.5)\n","cbar.ax.set_ylabel('Count')\n","# set ticks to represent hours in range 0 - 11:45\n","ticks = np.arange(0, 48, 4)\n","ax.set_xticks(ticks)\n","ax.set_yticks(ticks)\n","ax.set_xticklabels([f'{i:02d}:00' for i in range(0, 12)])\n","ax.set_yticklabels([f'{i:02d}:00' for i in range(0, 12)])\n","# set labels\n","ax.set_title('Confusion Matrix 48 Class ResNet')\n","ax.set_xlabel('Predicted')\n","ax.set_ylabel('Actual')\n","# rotate x labels\n","plt.setp(ax.get_xticklabels(), rotation=-45, ha='left', rotation_mode='anchor')\n","fig.tight_layout()\n","fig.savefig(DIRS['plots'] + 'cm_48_class_resnet.png', dpi=300)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# get predictions on some random samples and plot the image along with true and predicted time\n","fig, axes = plt.subplots(1, 5, figsize=(20, 5))\n","for ax in axes:\n","    i = np.random.randint(0, X_test.shape[0])\n","    ax.imshow(X_test[i])\n","    min_to_human_time = lambda m: f'{m // 60:02d}:{m % 60:02d}'\n","    pred = y_pred[i] * 15\n","    true = y_test[i] * 15\n","    ax.set_title(f'Pred: {min_to_human_time(pred)} - True: {min_to_human_time(true)}')\n","    ax.axis('off')\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.8 64-bit (microsoft store)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"vscode":{"interpreter":{"hash":"f8198290f8e7f9ab333311b4f983462626a5afe6e07a783926ceda863ef228ef"}}},"nbformat":4,"nbformat_minor":4}
