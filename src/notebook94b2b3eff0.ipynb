{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2021-11-10T13:01:43.598562Z","iopub.status.busy":"2021-11-10T13:01:43.598284Z","iopub.status.idle":"2021-11-10T13:01:52.166704Z","shell.execute_reply":"2021-11-10T13:01:52.165866Z","shell.execute_reply.started":"2021-11-10T13:01:43.598507Z"},"trusted":true},"outputs":[],"source":["from __future__ import print_function\n","import tensorflow as tf\n","import tensorflow.keras\n","from tensorflow.keras.datasets import mnist, fashion_mnist\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Flatten\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D\n","from tensorflow.keras import backend as K\n","import numpy as np\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-10T13:01:52.169559Z","iopub.status.busy":"2021-11-10T13:01:52.169251Z","iopub.status.idle":"2021-11-10T13:01:52.179226Z","shell.execute_reply":"2021-11-10T13:01:52.177574Z","shell.execute_reply.started":"2021-11-10T13:01:52.169505Z"},"trusted":true},"outputs":[],"source":["# # Define common sense loss described in the assignment description\n","# def common_sense_loss_hours(y_true, y_pred):\n","#     return K.mean(K.abs(K.minimum(K.abs(y_true - y_pred), K.ones_like(y_true) * 12 - K.abs(y_true - y_pred))))\n","\n","# def common_sense_loss_minutes(y_true, y_pred):\n","#     return K.mean(K.abs(K.minimum(K.abs(y_true - y_pred), K.ones_like(y_true) * 60 - K.abs(y_true - y_pred))))\n","\n","# Define ResNet model\n","def resnet():\n","    \"\"\"\n","    - ResNet model pretrained on 1000 class imagenet data set\n","    - ResNet 34 is loaded (34 deep convolutional layers)\n","    - The top of the ResNet model is excluded\n","    - Three layers are added to end of ResNet, a GAPooling and two dense layers\n","    - Last layer has linear activation to predict continuous regression value\n","    \"\"\"\n","    ResNet, preprocess_input = Classifiers.get('resnet34')\n","\n","    # Build ResNet model with correct input shape, weights loaded from 1000 class imagenet, top is exluced\n","    base_model = ResNet(input_shape=(150, 150, 3), weights='imagenet', include_top=False)\n","    x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n","    flatten = tf.keras.layers.Dense(256, activation='relu')(x)\n","    output = tf.keras.layers.Dense(1, activation='linear')(flatten)\n","    \n","    # Add extra layers and create Keras model\n","    model = tf.keras.models.Model(inputs=[base_model.input], outputs=[output])\n","    \n","    # Compile model with adam optimizer and custom loss/MSE\n","    model.compile(optimizer=\"adam\", loss=tf.keras.losses.MeanSquaredError(), metrics=[tf.keras.losses.MeanAbsoluteError()])\n","    \n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-10T13:01:52.181152Z","iopub.status.busy":"2021-11-10T13:01:52.180892Z","iopub.status.idle":"2021-11-10T13:01:54.280814Z","shell.execute_reply":"2021-11-10T13:01:54.280062Z","shell.execute_reply.started":"2021-11-10T13:01:52.181118Z"},"trusted":true},"outputs":[],"source":["def train_test_split(X, y, test_size=0.2, shuffle=False):\n","    if shuffle:\n","        data = [(x, y) for x, y in zip(X, y)]\n","        np.random.shuffle(data)\n","        X, y = [d[0] for d in data], [d[1] for d in data]\n","        num_samples_train = int((1 - test_size) * len(data))\n","        return np.array(X[:num_samples_train]), np.array(X[num_samples_train:]), np.array(y[:num_samples_train]), np.array(y[num_samples_train:])\n","    \n","    num_samples_train = int((1 - test_size) * len(X))\n","    return X[:num_samples_train], X[num_samples_train:], y[:num_samples_train], y[num_samples_train:]\n","    \n","        \n","# Data processing hours\n","data = np.load(\"../input/time-data/images.npy\")\n","labels = np.load(\"../input/time-data/labels.npy\")\n","\n","X = np.stack([data]*3, axis=-1)\n","\n","\n","x_train, x_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, shuffle=True)\n","\n","del X, data\n","\n","y_train_hours = np.expand_dims(np.array([x[0] for x in y_train], dtype=\"float32\"), axis=-1)\n","y_train_minutes = np.expand_dims(np.array([x[1] for x in y_train], dtype=\"float32\"), axis=-1)\n","\n","y_test_hours = np.expand_dims(np.array([x[0] for x in y_test], dtype=\"float32\"), axis=-1)\n","y_test_minutes = np.expand_dims(np.array([x[1] for x in y_test], dtype=\"float32\"), axis=-1)\n","\n","def cv_generator(X, y, n_folds=5):\n","    folds = np.array_split([(x, y) for x, y in zip(X, y)], n_folds)\n","    fold = 0\n","    while True:\n","        train_samples = [item for sublist in [f for i, f in enumerate(folds) if i != fold] for item in sublist]\n","        x_train = np.array([x[0] for x in train_samples])\n","        y_train = np.array([x[1] for x in train_samples])\n","        x_test = np.array([x[0] for x in folds[fold]])\n","        y_test = np.array([x[1] for x in folds[fold]])\n","        yield x_train, x_test, y_train, y_test\n","        fold += 1\n","        \n","def evaluate_common_sense(model_hours, model_minutes, x_test, y_test):\n","    y_pred_hours = model_hours.predict(x_test)\n","    y_pred_minutes = model_minutes.predict(x_test)\n","\n","    y_pred = [round(y_pred_hours[i][0]) + round(y_pred_minutes[i][0]) / 60 for i in range(len(x_test))]\n","    y_true = [y_test_hours[i][0] + y_test_minutes[i][0] / 60 for i in range(len(y_test_hours))]\n","\n","    print(y_pred_hours[:20])\n","    print(y_pred_minutes[:20])\n","    print(y_test[:20])\n","\n","    common_sense_error = sum([min(abs(y_true[i] - y_pred[i]), 12.0 - abs(y_true[i] - y_pred[i])) for i in range(len(y_true))]) / len(y_true) * 60\n","    print(f\"Mean Common Sense Error for test samples is {common_sense_error}\")\n","    return common_sense_error\n","    \n","    \n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-10T13:01:54.28244Z","iopub.status.busy":"2021-11-10T13:01:54.282014Z","iopub.status.idle":"2021-11-10T13:07:30.734626Z","shell.execute_reply":"2021-11-10T13:07:30.73335Z","shell.execute_reply.started":"2021-11-10T13:01:54.282403Z"},"trusted":true},"outputs":[],"source":["cv_results = []\n","cv_data = cv_generator(np.concatenate((x_train, x_test), axis=0), np.concatenate((y_train, y_test), axis=0))\n","\n","for _ in range(5):\n","    x_train, x_test, y_train, y_test = next(cv_data)\n","    \n","    model_hours = resnet()\n","    model_minutes = resnet()\n","    \n","    y_train_hours = np.expand_dims(np.array([x[0] for x in y_train], dtype=\"float32\"), axis=-1)\n","    y_train_minutes = np.expand_dims(np.array([x[1] for x in y_train], dtype=\"float32\"), axis=-1)\n","\n","    y_test_hours = np.expand_dims(np.array([x[0] for x in y_test], dtype=\"float32\"), axis=-1)\n","    y_test_minutes = np.expand_dims(np.array([x[1] for x in y_test], dtype=\"float32\"), axis=-1)\n","\n","    # Fit and evaluate model\n","    model_hours.fit(x_train, y_train_hours,\n","              batch_size=256,\n","              epochs=19,\n","              verbose=1,\n","              validation_data=(x_test, y_test_hours))\n","\n","    score = model_hours.evaluate(x_test, y_test_hours, verbose=0)\n","    print('Test loss:', score[0])\n","    print('Test accuracy:', score[1])\n","\n","    model_minutes.fit(x_train, y_train_minutes,\n","              batch_size=256,\n","              epochs=19,\n","              validation_data=(x_test, y_test_minutes))\n","\n","    score = model_minutes.evaluate(x_test, y_test_minutes, verbose=0)\n","    print('Test loss:', score[0])\n","    print('Test accuracy:', score[1])\n","    del x_train\n","    cv_results.append(evaluate_common_sense(model_hours, model_minutes, x_test, y_test))\n","    del model_hours, model_minutes\n","\n","print(f\"Mean of all Mean Common Sense Errors is {sum(cv_results) / len(cv_results)}\")\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
